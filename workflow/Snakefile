from snakemake.utils import validate
from snakemake.utils import min_version
import pandas as pd
import os

from itertools import product

min_version("7.18")

DATA_DIR = "/nfs/data/patients_networks/data"
RESULT_DIR = "results"
WORKFLOW_DIR=str(os.path.abspath(str(workflow.current_basedir)+"/../"))
DB_DIR = os.path.join(WORKFLOW_DIR, "neo4j_db")
DB_PW = "fMb8TF5U?kY-HP"


META_FILE = "expression_raw/TCGA_phenotype_denseDataOnlyDownload.tsv"
CLINICAL_FILE = "expression_raw/Survival_SupplementalTable_S1_20171025_xena_sp"
MAPPING_FILE = "expression_raw/probeMap%2Fgencode.v23.annotation.gene.probemap"

RAW_EXPR_COUNTS_FILE = "expression_raw/tcga_gene_expected_count"
RAW_EXPR_TPM_FILE = "expression_raw/tcga_RSEM_gene_tpm"

KNOWN_TFS_FILE = "genie3/TF_names_v_1.01.txt"

CANCER_TYPES = ["BRCA", "COAD", "HNSC", "KIRC", "KIRP", "LIHC", "LUAD", "LUSC", "PRAD", "STAD", "THCA", ]
NORM_METHODS = ["tpm", "mrn"]
METHODS = ["dysregnet", "dysregnet_no_direction", "ssn"]
REF_NET_TYPES = ['exp', 'string', 'genie3_shared', 'genie3_individual']
OL_METHODS = METHODS+["dysregnet_signed","dysregnet_no_direction_signed"] # method names, dysregnet also has "_signed" extension

# map different normalization methods to their sample sheets
META_MAP = {"tpm":"tpm", "mrn":"expected_counts"}




wildcard_constraints:
    cancer_type="|".join(CANCER_TYPES+["shared"]),
    norm_method="|".join(NORM_METHODS),
    method = "|".join(METHODS),
    ol_method = "|".join(OL_METHODS)

# helper functions

def get_ref_net_path(wildcards):
    ref_net = wildcards.ref_net
    if ref_net.startswith("genie3"):
        splitted = ref_net.split("_")
        return f"{RESULT_DIR}/reference_networks/genie3/{splitted[1]}/{ref_net}.csv"
    elif ref_net.startswith("exp"):
        return f"{RESULT_DIR}/reference_networks/HTRIdb_data.csv"

    elif ref_net.startswith("string"):
        return f"{RESULT_DIR}/reference_networks/string.csv"

    else:
        return f"{RESULT_DIR}/reference_networks/{ref_net}.csv"


def get_genie3_patient_network_outputs(method, norm_method, cancer_types = CANCER_TYPES):
    outputs = []
    for cancer_type in cancer_types:
        pattern = f"{RESULT_DIR}/patient_networks/{cancer_type}/{method}/{norm_method}-genie3_{{network_type}}_{norm_method}.top_100k.fea"
        individual = pattern.format(network_type=cancer_type)
        shared = pattern.format(network_type="shared")
        outputs.append(individual)
        outputs.append(shared)
    return outputs

def get_shared_ref_net_names(norm_method):
    shared_network_names =  ["exp",
                             "string",
                             f"genie3_shared_{norm_method}.top_100k"
                             ]
    return shared_network_names

def get_ref_net_types(norm_method):
    return get_shared_ref_net_names(norm_method) + [f"genie3_individual_{norm_method}.top_100k"]

def get_ref_net_names(ref_net_type, norm_method, cancer_types = CANCER_TYPES):
    """
    Purpose of this method is, to get the different ref nets used for genie3_individual for each cancer
    :param ref_net_type: string has to start with 'exp', 'string', 'genie3_shared', or 'genie3_individual'
    :param norm_method: the norm method
    :param cancer_types: list of cancer types
    :return: a list with the ref net used for each cancer type in cancer_types
    """

    if ref_net_type.startswith("exp"):
        return ["exp"] * len(cancer_types)
    elif ref_net_type.startswith("string"):
        return ["string"] * len(cancer_types)
    elif ref_net_type.startswith("genie3_shared"):
        return [f"genie3_shared_{norm_method}.top_100k"] * len(cancer_types)
    elif ref_net_type.startswith("genie3_individual"):
        return [f"genie3_{cancer_type}_{norm_method}.top_100k" for cancer_type in cancer_types]
    else:
        raise Exception(f"Unknown ref_net_type: {ref_net_type}")



network_df = pd.DataFrame.from_dict(
    [
        {"cancer_type": combi[2], "norm_method": combi[1], "ref_net": get_ref_net_names(combi[0],combi[1],[combi[2]])[0]}
        for combi in product(REF_NET_TYPES,NORM_METHODS,CANCER_TYPES)
    ]
)

#### reference network preparation ####

rule prepare_HTRIdb:
    input:
        f"{DATA_DIR}/reference_networks/HTRIdb_data.csv"
    output:
        f"{RESULT_DIR}/reference_networks/HTRIdb_data.csv"
    log:
        "logs/prepare_HTRIdb.log"
    shell:
        "python workflow/scripts/prepare_HTRIdb.py --input {input} --output {output} >& {log}"


rule prepare_string:
    input:
        f"{DATA_DIR}/reference_networks/string.csv"
    output:
        f"{RESULT_DIR}/reference_networks/string.csv"
    log:
        "logs/prepare_string.log"
    shell:
        "python workflow/scripts/prepare_string.py --input {input} --output {output} >& {log}"




#### expression data pre-processing ####

rule process_pancan_expected_counts:
    input:
        meta = f"{DATA_DIR}/{META_FILE}",
        clinical = f"{DATA_DIR}/{CLINICAL_FILE}",
        expr = f"{DATA_DIR}/{RAW_EXPR_COUNTS_FILE}",
        mapping = f"{DATA_DIR}/{MAPPING_FILE}",
    params:
        out_dir = f"{RESULT_DIR}/expression_processed",
    output:
        expand("{result_dir}/expression_processed/{cancer_type}/expected_counts.csv",
            result_dir=RESULT_DIR, cancer_type=CANCER_TYPES),
        expand("{result_dir}/expression_processed/{cancer_type}/expected_counts_meta.csv",
            result_dir=RESULT_DIR, cancer_type=CANCER_TYPES)
    log:
        "logs/process_pancan_expected_counts.log"
    shell:
        "python workflow/scripts/process_pancan_expected_counts.py "
        "--meta {input.meta} "
        "--clinical {input.clinical} "
        "--expr {input.expr} "
        "--mapping {input.mapping} "
        "--out_dir {params.out_dir} "
        " >& {log}"


rule process_pancan_tpm:
    input:
        meta = f"{DATA_DIR}/{META_FILE}",
        clinical = f"{DATA_DIR}/{CLINICAL_FILE}",
        expr = f"{DATA_DIR}/{RAW_EXPR_TPM_FILE}",
        mapping = f"{DATA_DIR}/{MAPPING_FILE}",
    params:
        out_dir = f"{RESULT_DIR}/expression_processed",
    output:
        expand("{result_dir}/expression_processed/{cancer_type}/tpm.csv",
            result_dir=RESULT_DIR, cancer_type=CANCER_TYPES),
        expand("{result_dir}/expression_processed/{cancer_type}/tpm_meta.csv",
            result_dir=RESULT_DIR, cancer_type=CANCER_TYPES)
    log:
        "logs/process_pancan_tpm.log"
    shell:
        "python workflow/scripts/process_pancan_tpm.py "
        "--meta {input.meta} "
        "--clinical {input.clinical} "
        "--expr {input.expr} "
        "--mapping {input.mapping} "
        "--out_dir {params.out_dir} "
        ">& {log} "


rule mrn_normalization:
    input:
        expr=f"{RESULT_DIR}/expression_processed/{{cancer_type}}/expected_counts.csv",
        meta=f"{RESULT_DIR}/expression_processed/{{cancer_type}}/expected_counts_meta.csv",
    output:
        f"{RESULT_DIR}/expression_processed/{{cancer_type}}/mrn.csv"
    log:
        "logs/mrn_normalization/mrn_normalization_{cancer_type}.log"
    threads: 8
    shell:
        "Rscript workflow/scripts/mrn_normalization.R {input.expr} {input.meta} {output} >& {log}"


#### methylation data pre-processing

rule methylation_zscoring:
    input:
        methylation=f"{DATA_DIR}/omics_analysis/methylation.csv",
        meta=f"{DATA_DIR}/{META_FILE}",
    output:
        f"{DATA_DIR}/omics_analysis/methylation_absolute_zscores.csv"
    log:
        "logs/methylation_zscoring.log"
    shell:
        "python workflow/scripts/methylation_zscoring.py "
        "--methylation {input.methylation} "
        "--meta {input.meta} "
        "--output {output} &> {log}"


#### reference network creation ####

rule genie3:
    input:
        expr = f"{RESULT_DIR}/expression_processed/{{cancer_type}}/{{norm_method}}.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
        known_tfs = f"{DATA_DIR}/{KNOWN_TFS_FILE}",
    output:
        f"{RESULT_DIR}/reference_networks/genie3/{{cancer_type}}/genie3_{{cancer_type}}_{{norm_method}}.csv"

    log:
        "logs/genie3/genie3_{cancer_type}_{norm_method}.log"
    threads: 30
    shell:
        "Rscript workflow/scripts/genie_run.R "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--known_tfs {input.known_tfs} "
        "--threads {threads} "
        "--output {output} "
        ">& {log} "


rule genie3_shared:
    input:
        expand("{result_dir}/reference_networks/genie3/{cancer_type}/genie3_{cancer_type}_{{norm_method}}.csv",
            result_dir=RESULT_DIR, cancer_type=CANCER_TYPES),
    output:
        f"{RESULT_DIR}/reference_networks/genie3/shared/genie3_shared_{{norm_method}}.csv"
    log:
        "logs/genie3_shared/genie3_shared_{norm_method}.log"
    resources:
        io=1
    shell:
        "python workflow/scripts/genie3_shared.py --input {input} --output {output} &> {log}"


rule genie3_top:
    input:
        f"{RESULT_DIR}/reference_networks/genie3/{{cancer_type}}/genie3_{{cancer_type}}_{{norm_method}}.csv"
    output:
        f"{RESULT_DIR}/reference_networks/genie3/{{cancer_type}}/genie3_{{cancer_type}}_{{norm_method}}.top_{{top_k}}k.csv"
    log:
        "logs/genie3_top/genie3_{cancer_type}_{norm_method}.top_{top_k}k.log"
    resources:
        io=1
    shell:
        "python workflow/scripts/genie3_top.py --input {input} --top_k {wildcards.top_k} --output {output} &> {log}"



#### patient-specific network creation ####

rule dysregnet:
    input:
        expr = f"{RESULT_DIR}/expression_processed/{{cancer_type}}/{{norm_method}}.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
        grn =  get_ref_net_path
    output:
        networks = f"{RESULT_DIR}/patient_networks/{{cancer_type}}/dysregnet/{{norm_method}}-{{ref_net}}.fea",
        stats = f"{RESULT_DIR}/patient_networks/{{cancer_type}}/dysregnet/{{norm_method}}-{{ref_net}}-stats.csv",

    log:
        "logs/dysregnet/{cancer_type}/{norm_method}-{ref_net}.log"
    shell:
        "python workflow/scripts/dysregnet_run.py "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--output {output.networks} "
        "--output_stats {output.stats} " 
        "&> {log}"

rule dysregnet_no_direction:
    input:
        expr = f"{RESULT_DIR}/expression_processed/{{cancer_type}}/{{norm_method}}.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
        grn =  get_ref_net_path
    output:
        networks = f"{RESULT_DIR}/patient_networks/{{cancer_type}}/dysregnet_no_direction/{{norm_method}}-{{ref_net}}.fea",
        stats = f"{RESULT_DIR}/patient_networks/{{cancer_type}}/dysregnet_no_direction/{{norm_method}}-{{ref_net}}-stats.csv",

    log:
        "logs/dysregnet_no_direction/{cancer_type}/{norm_method}-{ref_net}.log"
    shell:
        "python workflow/scripts/dysregnet_run.py "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--no_direction "
        "--output {output.networks} "
        "--output_stats {output.stats} " 
        "&> {log}"


rule ssn:
    input:
        expr = f"{RESULT_DIR}/expression_processed/{{cancer_type}}/{{norm_method}}.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
        grn =  get_ref_net_path
    output:
        f"{RESULT_DIR}/patient_networks/{{cancer_type}}/ssn/{{norm_method}}-{{ref_net}}.fea"
    log:
        "logs/ssn/{cancer_type}/{norm_method}-{ref_net}.log"
    shell:
        "python workflow/scripts/ssn_run.py "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--output {output} "
        "&> {log}"


rule lioness:
    input:
        expr = f"{RESULT_DIR}/expression_processed/{{cancer_type}}/{{norm_method}}.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
        grn =  get_ref_net_path
    output:
        f"{RESULT_DIR}/patient_networks/{{cancer_type}}/lioness/{{norm_method}}-{{ref_net}}.fea"
    log:
        "logs/lioness/{cancer_type}/{norm_method}-{ref_net}.log"
    benchmark:
        "logs/lioness/{cancer_type}/{norm_method}-{ref_net}.txt"
    shell:
        "Rscript workflow/scripts/lioness_run.R "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--output {output} "
        "&> {log}"



#### benchmark and omics analysis ####

rule compute_overlap_shared:
    input:
        expand("{result_dir}/patient_networks/{cancer_type}/{{method}}/{{norm_method}}-{{ref_net}}.fea",
            result_dir=RESULT_DIR,cancer_type=CANCER_TYPES),
    output:
        edges = f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{method}}/overlap_edges-{{norm_method}}-{{ref_net}}.fea",
        nodes = f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{method}}/overlap_nodes-{{norm_method}}-{{ref_net}}.fea"
    log:
        "logs/compute_overlap_shared/{method}/overlap-{norm_method}-{ref_net}.log"
    threads: 20
    shell:
        "python workflow/scripts/compute_overlap.py "
        "--input {input} "
        "--threads {threads} "
        "--shared "
        "--output_edges {output.edges} "
        "--output_nodes {output.nodes} "
        "&> {log}"

rule compute_overlap_shared_signed:
    input:
        expand("{result_dir}/patient_networks/{cancer_type}/{{method}}/{{norm_method}}-{{ref_net}}.fea",
            result_dir=RESULT_DIR,cancer_type=CANCER_TYPES),
    output:
        edges = f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{method}}_signed/overlap_edges-{{norm_method}}-{{ref_net}}.fea",
        nodes = f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{method}}_signed/overlap_nodes-{{norm_method}}-{{ref_net}}.fea"
    log:
        "logs/compute_overlap_shared/{method}_signed/overlap-{norm_method}-{ref_net}.log"
    threads: 20
    benchmark:
        "logs/compute_overlap_shared/{method}_signed/overlap-{norm_method}-{ref_net}.benchmark.txt"
    shell:
        "python workflow/scripts/compute_overlap.py "
        "--input {input} "
        "--threads {threads} "
        "--shared "
        "--signed "
        "--output_edges {output.edges} "
        "--output_nodes {output.nodes} "
        "&> {log}"


rule clustering_shared:
    input:
        overlaps_edges=f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{ol_method}}/overlap_edges-{{norm_method}}-{{ref_net}}.fea",
        overlaps_nodes=f"{RESULT_DIR}/benchmark/compute_overlap_shared/{{ol_method}}/overlap_nodes-{{norm_method}}-{{ref_net}}.fea",
        meta=f"{DATA_DIR}/{META_FILE}",
    output:
        edges=f"{RESULT_DIR}/figures/clustering_shared/{{ol_method}}/{{ol_method}}-edges-{{norm_method}}-{{ref_net}}.png",
        nodes=f"{RESULT_DIR}/figures/clustering_shared/{{ol_method}}/{{ol_method}}-nodes-{{norm_method}}-{{ref_net}}.png",
    log:
        "logs/clustering_shared/{ol_method}/{norm_method}-{ref_net}.log"
    benchmark:
        "logs/clustering_shared/{ol_method}/{norm_method}-{ref_net}.benchmark.txt"
    shell:
        "python workflow/scripts/clustering.py "
        "--overlaps_edges {input.overlaps_edges} "
        "--overlaps_nodes {input.overlaps_nodes} "
        "--meta {input.meta} "
        "--output_edges {output.edges} "
        "--output_nodes {output.nodes} "
        "&> {log}"


rule clustering_benchmark_shared:
    input:
        input = lambda wildcards:
            expand("{result_dir}/benchmark/compute_overlap_shared/{method}/overlap_edges-{{norm_method}}-{ref_net}.fea",
                result_dir=RESULT_DIR, method=OL_METHODS, ref_net=get_shared_ref_net_names(wildcards.norm_method)
            ),
        meta = f"{DATA_DIR}/{META_FILE}",
    output:
        f"{RESULT_DIR}/figures/clustering_benchmark_shared/f1-{{norm_method}}.png"
    log:
        "logs/clustering_benchmark_shared/f1-{norm_method}.log"
    shell:
        "python workflow/scripts/clustering_benchmark.py "
        "--input {input.input} "
        "--meta {input.meta} "
        "--output {output} "
        "&> {log}"


rule methylation_tests:
    input:
        methylation = f"{DATA_DIR}/omics_analysis/methylation.csv",
        networks = lambda wildcards: expand("{result_dir}/patient_networks/{cancer_type}/{{method}}/{{norm_method}}-{ref_net}.fea",
            zip,
            result_dir=[RESULT_DIR]*len(CANCER_TYPES), cancer_type=CANCER_TYPES, ref_net=get_ref_net_names(wildcards.ref_net_type, wildcards.norm_method)),
    output:
        local_out = f"{RESULT_DIR}/omics_analysis/methylation_tests/{{method}}/meth_tests_local-{{norm_method}}-{{ref_net_type}}.npy",
        global_out = f"{RESULT_DIR}/omics_analysis/methylation_tests/{{method}}/meth_tests_global-{{norm_method}}-{{ref_net_type}}.npy"
    log:
        "logs/methylation_tests/{method}/{norm_method}-{ref_net_type}.log"
    shell:
        "python workflow/scripts/methylation_tests.py "
        "--methylation {input.methylation} "
        "--networks {input.networks} "
        "--output_local {output.local_out} "
        "--output_global {output.global_out} "
        "&> {log}"


rule methylation_zscores_tests:
    input:
        methylation = rules.methylation_zscoring.output,
        networks = lambda wildcards: expand("{result_dir}/patient_networks/{cancer_type}/{{method}}/{{norm_method}}-{ref_net}.fea",
            zip,
            result_dir=[RESULT_DIR]*len(CANCER_TYPES), cancer_type=CANCER_TYPES, ref_net=get_ref_net_names(wildcards.ref_net_type, wildcards.norm_method)),
    output:
        local_out = f"{RESULT_DIR}/omics_analysis/methylation_zscores_tests/{{method}}/meth_tests_local-{{norm_method}}-{{ref_net_type}}.npy",
        global_out = f"{RESULT_DIR}/omics_analysis/methylation_zscores_tests/{{method}}/meth_tests_global-{{norm_method}}-{{ref_net_type}}.npy"
    log:
        "logs/methylation_zscores_tests/{method}/{norm_method}-{ref_net_type}.log"
    shell:
        "python workflow/scripts/methylation_tests.py "
        "--methylation {input.methylation} "
        "--networks {input.networks} "
        "--output_local {output.local_out} "
        "--output_global {output.global_out} "
        "&> {log}"


rule methylation_plots:
    input:
        inputs_local = lambda wildcards: expand(
            rules.methylation_tests.output.local_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
        ),
        inputs_global = lambda wildcards: expand(
            rules.methylation_tests.output.global_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
        ),
    output:
        f"{RESULT_DIR}/figures/methylation/methylation-{{norm_method}}.png"
    log:
        "logs/methylation_plots/-{norm_method}.log"
    shell:
        "python workflow/scripts/methylation_plots.py "
        "--inputs_local {input.inputs_local} "
        "--inputs_global {input.inputs_global} "
        "--output {output} "
        "&> {log}"


rule methylation_zscores_plots:
    input:
        inputs_local = lambda wildcards: expand(
            rules.methylation_zscores_tests.output.local_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
        ),
        inputs_global = lambda wildcards: expand(
            rules.methylation_zscores_tests.output.global_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
        ),
    output:
        f"{RESULT_DIR}/figures/methylation/methylation_zscores-{{norm_method}}.png"
    log:
        "logs/methylation_zscores_plots/{norm_method}.log"
    shell:
        "python workflow/scripts/methylation_plots.py "
        "--inputs_local {input.inputs_local} "
        "--inputs_global {input.inputs_global} "
        "--output {output} "
        "&> {log}"



rule mutation_tests:
    input:
        mutations = f"{DATA_DIR}/omics_analysis/somatic_mutations_Unified.csv",
        networks = lambda wildcards: expand("{result_dir}/patient_networks/{cancer_type}/{{method}}/{{norm_method}}-{ref_net}.fea",
            zip,
            result_dir=[RESULT_DIR]*len(CANCER_TYPES), cancer_type=CANCER_TYPES, ref_net=get_ref_net_names(wildcards.ref_net_type, wildcards.norm_method)),
    output:
        local_out = f"{RESULT_DIR}/omics_analysis/mutation_tests/{{method}}/mut_tests_local-{{norm_method}}-{{ref_net_type}}-min{{n_mut_patients}}.csv",
        global_out = f"{RESULT_DIR}/omics_analysis/mutation_tests/{{method}}/mut_tests_global-{{norm_method}}-{{ref_net_type}}-min{{n_mut_patients}}.csv"
    log:
        "logs/mutation_tests/{method}/{norm_method}-{ref_net_type}-min{n_mut_patients}.log"
    conda:
        "envs/mutation_tests.yaml"
    shell:
        "python workflow/scripts/mutation_tests.py "
        "--mutations {input.mutations} "
        "--networks {input.networks} "
        "--n_mut_patients {wildcards.n_mut_patients} "
        "--output_local {output.local_out} "
        "--output_global {output.global_out} "
        "&> {log}"


rule mutation_plots:
    input:
        inputs_local = lambda wildcards: expand(
            rules.mutation_tests.output.local_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
            n_mut_patients=wildcards.n_mut_patients,
        ),
        inputs_global = lambda wildcards: expand(
            rules.mutation_tests.output.global_out,
            ref_net_type=get_ref_net_types(wildcards.norm_method),
            method=METHODS,
            norm_method=wildcards.norm_method,
            n_mut_patients=wildcards.n_mut_patients,
        ),
    output:
        both=f"{RESULT_DIR}/figures/mutation_analysis/mutation-{{norm_method}}-min{{n_mut_patients}}.png",
        global_pvals=f"{RESULT_DIR}/figures/mutation_analysis/mutation_global-{{norm_method}}-min{{n_mut_patients}}.png"
    log:
        "logs/mutation_plots/{norm_method}-min{n_mut_patients}.log"
    shell:
        "python workflow/scripts/mutation_plots.py "
        "--inputs_local {input.inputs_local} "
        "--inputs_global {input.inputs_global} "
        "--output {output.both} "
        "--output_global {output.global_pvals} "
        "&> {log}"


rule model_stats_plots:
    input:
        lambda wildcards: expand(f"{RESULT_DIR}/patient_networks/{{cancer_type}}/dysregnet/{{norm_method}}-{{ref_net}}-stats.csv", zip,
            cancer_type = network_df.query(f"norm_method=='{wildcards.norm_method}'").cancer_type,
            norm_method=network_df.query(f"norm_method=='{wildcards.norm_method}'").norm_method,
            ref_net=network_df.query(f"norm_method=='{wildcards.norm_method}'").ref_net,
        )
    output:
        dir=directory(f"{RESULT_DIR}/figures/model_stats/{{norm_method}}/"),
        stats_summary=f"{RESULT_DIR}/model_stats_summary/{{norm_method}}-model_stats_summary.tsv"
    log:
        "logs/model_stats_plots/{norm_method}.log"
    shell:
        "mkdir -p {output.dir} && "
        "python workflow/scripts/model_stats_plots.py "
        "--inputs {input} "
        "--norm_method {wildcards.norm_method} "
        "--output_dir {output.dir} "
        "--output_stats_summary {output.stats_summary} "
        "&> {log}"


rule total_dysregulations_plots:
    input:
        lambda wildcards: expand([f"{RESULT_DIR}/patient_networks/{{cancer_type}}/{method}/{{norm_method}}-{{ref_net}}.fea" for method in METHODS], zip,
            cancer_type = network_df.query(f"norm_method=='{wildcards.norm_method}'").cancer_type,
            norm_method=network_df.query(f"norm_method=='{wildcards.norm_method}'").norm_method,
            ref_net=network_df.query(f"norm_method=='{wildcards.norm_method}'").ref_net,
        )
    output:
        f"{RESULT_DIR}/figures/total_dysregulations/total_dysregulations-{{norm_method}}.png",
    log:
        "logs/total_dysregulations_plots/{norm_method}.log"
    shell:
        "python workflow/scripts/total_dysregulations_plots.py "
        "--inputs {input} "
        "--output {output} "
        "&> {log}"


rule cancer_stage_tests:
    input:
        network = lambda wildcards:
            expand("{result_dir}/patient_networks/{{cancer_type}}/{{method}}/{{norm_method}}-{ref_net}.fea",
            result_dir=RESULT_DIR, ref_net=get_ref_net_names(wildcards.ref_net_type, wildcards.norm_method, cancer_types=[wildcards.cancer_type])),
        meta = lambda wildcards:
            f"{RESULT_DIR}/expression_processed/{wildcards.cancer_type}/{META_MAP[wildcards.norm_method]}_meta.csv",
    output:
        pvals = touch(f"{RESULT_DIR}/cancer_stage_analysis/{{cancer_type}}/{{method}}/stage_tests-{{norm_method}}-{{ref_net_type}}.csv")
    log:
        f"logs/cancer_stage_tests/{{cancer_type}}/{{method}}/stage_tests-{{norm_method}}-{{ref_net_type}}.log"
    shell:
        "python workflow/scripts/cancer_stage_tests.py "
        "--network {input.network} "
        "--meta {input.meta} "
        "--output_pvals {output.pvals} "
        "&> {log}"

rule cancer_stage_plots:
    input:
        lambda wildcards:
            expand(rules.cancer_stage_tests.output,
                method = METHODS,
                norm_method = wildcards.norm_method,
                cancer_type=CANCER_TYPES,
                ref_net_type=get_ref_net_types(wildcards.norm_method),
            )
    output:
        f"{RESULT_DIR}/figures/cancer_stage_analysis/cancer_stage-{{norm_method}}.png"
    log:
        f"logs/cancer_stage_plots/{{norm_method}}.log"
    shell:
        "python workflow/scripts/cancer_stage_plots.py "
        "--inputs {input} "
        "--output {output} "
        "&> {log}"



#### runtime benchmark ####

rule runtime_dysregnet:
    input:
        expr = f"{RESULT_DIR}/expression_processed/THCA/tpm.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/THCA/tpm_meta.csv",
        grn =  rules.prepare_HTRIdb.output
    output:
        networks = f"{RESULT_DIR}/runtime/method_output/dysregnet.fea",
        stats = f"{RESULT_DIR}/runtime/method_output/dysregnet-stats.csv",
    log:
        "logs/runtime/dysregnet.log"
    benchmark:
        repeat(f"{RESULT_DIR}/runtime/dysregnet.txt", 10)
    shell:
        "python workflow/scripts/dysregnet_run.py "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--output {output.networks} "
        "--output_stats {output.stats} " 
        "&> {log}"


rule runtime_ssn:
    input:
        expr = f"{RESULT_DIR}/expression_processed/THCA/tpm.csv",
        meta = lambda wildcards: f"{RESULT_DIR}/expression_processed/THCA/tpm_meta.csv",
        grn =  rules.prepare_HTRIdb.output
    output:
        f"{RESULT_DIR}/runtime/method_output/ssn.fea",
    log:
        "logs/runtime/ssn.log"
    benchmark:
        repeat(f"{RESULT_DIR}/runtime/ssn.txt", 10)
    shell:
        "python workflow/scripts/ssn_run.py "
        "--expr {input.expr} "
        "--meta {input.meta} "
        "--grn {input.grn} "
        "--output {output} "
        "&> {log}"


rule runtime_plots:
    input:
        rules.runtime_dysregnet.benchmark,
        rules.runtime_ssn.benchmark,
    output:
        f"{RESULT_DIR}/figures/runtime/runtime.png/"
    log:
        "logs/runtime_plots.log"
    shell:
        "python workflow/scripts/runtime_plots.py "
        "--input {input} "
        "--output {output} "
        "&> {log}"


#### database ####

# not part of the target rules
# load manually by running: snakemake --profile <profile> --force load_db
# old data <DB_DIR>/data has to be deleted manually before updating ist

localrules: provide_db, load_db

rule provide_db:
    output:
        service("neo4j_service_flag")
    shell:
        f'''
        ln -s /dev/random {{output}} &&
        docker rm -f -v neo4j_load_db &&
        mkdir -p {DB_DIR}/data && 
        mkdir -p {DB_DIR}/csv && 
        mkdir -p {DB_DIR}/logs &&
        chmod -R 777 {DB_DIR} &&
        docker run \
        --user $UID:$GID \
        --name neo4j_load_db \
        -p7474:7474 -p7687:7687 \
        -v {DB_DIR}/data:/data \
        -v {DB_DIR}/csv:/import \
        -v {DB_DIR}/logs:/logs \
        -v {WORKFLOW_DIR}/assets/neo4j_conf:/conf \
        --env NEO4J_AUTH=neo4j/{DB_PW} \
        neo4j:5.11.0
        '''


rule load_db:
    input:
        methylation=f"{DATA_DIR}/omics_analysis/methylation.csv",
        mutations = f"{DATA_DIR}/omics_analysis/somatic_mutations_Unified.csv",
        networks = expand(rules.dysregnet.output.networks, cancer_type=CANCER_TYPES, norm_method="tpm", ref_net = "genie3_shared_tpm.top_100k"),
        stats = expand(rules.dysregnet.output.stats, cancer_type=CANCER_TYPES, norm_method="tpm", ref_net = "genie3_shared_tpm.top_100k"),
        db_socket = rules.provide_db.output
    output:
        db_flag = touch(f'{DB_DIR}/flag.txt')
    log:
        "logs/load_db.log"
    params:
        csv_dir= f'{DB_DIR}/csv/'
    conda:
        "envs/neo4j_python.yaml"
    shell:
        "(python workflow/scripts/load_db_csv.py "
        "--methylation {input.methylation} "
        "--mutations {input.mutations} "
        "--networks {input.networks} "
        "--stats {input.stats} "
        "--csv_dir {params.csv_dir} "
        "--pw {DB_PW} "
        "&& touch {output.db_flag}) "
        "&> {log}"


rule all:
    input:
        # patient-specific network outputs
        #get_genie3_patient_network_outputs(method="dysregnet",norm_method="tpm"),
        #get_genie3_patient_network_outputs(method="ssn", norm_method="tpm"),
        #get_genie3_patient_network_outputs(method="dysregnet", norm_method="mrn"),
        #get_genie3_patient_network_outputs(method="ssn", norm_method="mrn"),
        expand("{result_dir}/patient_networks/{cancer_type}/{method}/{norm_method}-{ref_net}.fea",
            result_dir=RESULT_DIR,
            cancer_type = CANCER_TYPES,
            method = METHODS,
            norm_method = NORM_METHODS,
            ref_net =["exp","string"]
        ),

        # clustering heatmaps shared
        expand("{result_dir}/figures/clustering_shared/{method}/{method}-edges-{norm_method}-{ref_net}.png",
            result_dir=RESULT_DIR, method=OL_METHODS, norm_method="tpm", ref_net=["exp", "string"]
        ),
        expand("{result_dir}/figures/clustering_shared/{method}/{method}-edges-{norm_method}-genie3_shared_{norm_method}.top_100k.png",
            result_dir=RESULT_DIR, method=OL_METHODS, norm_method="tpm"
        ),

        # clustering benchmark shared
        expand(rules.clustering_benchmark_shared.output, norm_method="tpm"),

        # methylation plots
        expand(rules.methylation_plots.output, method=METHODS, norm_method="tpm"),

        # methylation zscores plots
        expand(rules.methylation_zscores_plots.output, method=METHODS, norm_method="tpm"),

        # mutation tests
        [expand(rules.mutation_tests.output, method=METHODS, norm_method=norm_method, ref_net_type=get_ref_net_types(norm_method),  n_mut_patients=[2,4,6])
         for norm_method in NORM_METHODS],

        # mutation plots
        expand(rules.mutation_plots.output, norm_method="tpm", n_mut_patients=[2,4,6]),

        # model stats
        expand(rules.model_stats_plots.output, norm_method=NORM_METHODS),

        # cancer stage plots
        expand(rules.cancer_stage_plots.output, norm_method="tpm"),

        #total dysregulations plots
        expand(rules.total_dysregulations_plots.output, norm_method="tpm"),

        # run time benchmark
        rules.runtime_plots.output,

    default_target: True



